{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeMq02nPc-jD",
        "outputId": "462e3d81-6ff5-4e2e-cf5b-38c85d908a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "Vh-s9zF7P1F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRSBhA1UbBdT"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/KAGGLE_API_CREDENTIALS/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glckJscJbRa6"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brEQ4i8Zd8Wz"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d plameneduardo/a-covid-multiclass-dataset-of-ct-scans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDHPSDCueRB1"
      },
      "outputs": [],
      "source": [
        "!unzip /content/a-covid-multiclass-dataset-of-ct-scans.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfuO3rpcgKsW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets,transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqLzxbmNhZ8G"
      },
      "outputs": [],
      "source": [
        "# Define a transform to convert the images to tensors\n",
        "transform = transforms.Compose([transforms.Resize((224,224)),  # Resize all images to 224x224\n",
        "                                transforms.ToTensor()])  # Convert the images to tensors\n",
        "\n",
        "# Load the images from the 'root' directory\n",
        "dataset = datasets.ImageFolder('New_Data_CoV2', transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_Ki9F3WomgI"
      },
      "outputs": [],
      "source": [
        "test_split = 0.33\n",
        "shuffle_dataset = True\n",
        "random_seed=42\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(test_split * dataset_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bcW0RrZuft5"
      },
      "outputs": [],
      "source": [
        "if shuffle_dataset:\n",
        "  np.random.seed(42)\n",
        "  np.random.shuffle(indices)\n",
        "\n",
        "train_indices, test_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAhaLjHmhPrs"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOGy_e6U13RS"
      },
      "outputs": [],
      "source": [
        "class CovNetScan(nn.Module):\n",
        "  def __init__(self, input_shape,output):\n",
        "    super().__init__()\n",
        "    self.layers_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=35),\n",
        "        nn.BatchNorm1d(35),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=35, out_features=50),\n",
        "        nn.BatchNorm1d(50),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=50, out_features=40),\n",
        "        nn.Linear(in_features=40, out_features=output),\n",
        "    )\n",
        "  \n",
        "  def forward(self, X):\n",
        "    return self.layers_stack(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBbOW25N17cy"
      },
      "outputs": [],
      "source": [
        "input_shape = 3 * 224 * 224\n",
        "num_classes = 3\n",
        "model_0 = CovNetScan(input_shape = input_shape , output = num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvol7OhDb7Cz"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.06)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDbdahc_AhnX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "import copy\n",
        "best_report = None\n",
        "epochs = 100\n",
        "best_acc = 0.0\n",
        "best_model_weights = copy.deepcopy(model_0.state_dict())\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model_0.train()\n",
        "    for X,y in train_loader:\n",
        "        X,y = X.to(device),y.to(device)\n",
        "        y_pred = model_0(X)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "\n",
        "      with torch.inference_mode():\n",
        "          model_0.eval()\n",
        "          y_true = []\n",
        "          y_pred = []\n",
        "          \n",
        "          for X_test,y_test in tqdm(test_loader):\n",
        "              X_test,y_test = X_test.to(device),y_test.to(device)\n",
        "              y_test_pred = model_0(X_test)\n",
        "              test_loss = loss_fn(y_test_pred,y_test)\n",
        "              y_true.extend(y_test.cpu().numpy())\n",
        "              y_pred.extend(y_test_pred.argmax(dim=1).cpu().numpy())\n",
        "          \n",
        "          report = classification_report(y_true=y_true, y_pred=y_pred, target_names=dataset.classes, output_dict=True)\n",
        "          current_acc = report['accuracy']\n",
        "          if best_acc < current_acc: \n",
        "              best_acc = current_acc\n",
        "              best_model_weights = copy.deepcopy(model_0.state_dict())\n",
        "              best_report = report\n",
        "\n",
        "          \n",
        "\n",
        "print(best_report)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.load_state_dict(best_model_weights)\n",
        "torch.save(model_0.state_dict(),'Covid_CT_Scans')"
      ],
      "metadata": {
        "id": "vb92AzvY_mYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}